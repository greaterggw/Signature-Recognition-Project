
# Automated Signature Verification (Classical ML)

> **Portfolio Project â€” GitHub README**  
> Last updated: 2025-09-12

## ğŸ“Œ Problem Overview
Manual signature verification in elections is slow, subjective, and vulnerable to error. This project builds an **automated signature verification system** that classifies signatures as belonging to specific signer IDs, aiming to **improve accuracy, speed, and fairness** in verification workflows.

## ğŸ¯ Objectives
- **Accuracy**: Reliably classify signatures to the correct signer ID (multi-class).  
- **Efficiency**: Reduce time required compared to manual checks.  
- **Security & Fairness**: Support processes that ensure only valid votes are counted.

---

## ğŸ—‚ï¸ Data & Preprocessing
- **Images**: RGB signatures at **100Ã—100** resolution.
- **Total samples**: **21,120** images (after augmentation).
- **Task**: Multi-class classification (signer IDs).  
- **Augmentation**: Rotation, zoom, and shear (saved under `Images/augmented{1..9}` folders).
- **Flattening**: Each image â†’ **30,000 features**.
- **Dimensionality Reduction**: **PCA (95% variance)** â†’ **2,034 components**.
- **Split**: **70/30** train/test, stratified.
- **Scaling**: `StandardScaler` on features.

> Shapes captured directly from the notebook:
> - `images.shape` â†’ `(21120, 100, 100, 3)`  
> - `data.shape` (flattened) â†’ `(21120, 30000)`  
> - `X_pca.shape` â†’ `(21120, 2034)`  
> - Test set size (30%) â†’ `6336` samples

---

## ğŸ§  Models Evaluated
The following classical ML models were trained and compared on the same PCAâ€‘reduced feature set. Metrics below are from the notebookâ€™s printed **classification reports** (weighted values where applicable).

| Model | Accuracy | Notes |
|---|---:|---|
| **SVM (RBF, class_weight=balanced)** | **0.80** | Best overall; balanced precision/recall/F1; strong generalization |
| Random Forest | 0.71 | Solid performance, but lower than SVM on several classes |
| AdaBoost | 0.51 | Improved vs SGD, still notably below SVM |
| Logistic Regression | 0.39 | Underfit on this highâ€‘dimensional task |
| SGD Classifier | 0.39 | Lowest; struggled across multiple classes |

Additional evidence: the **SVM classification report** shows **weighted precision/recall/F1 â‰ˆ 0.80** over **6,336 test images**.

---

## ğŸ† Chosen Model
**Support Vector Machine (RBF kernel)** with `class_weight="balanced"` is the final choice due to the best accuracy and balanced perâ€‘class performance.  
The trained model is persisted as: **`svm_model.pkl`** (and scaled variant `svm_model_sc.pkl` if you train on scaled features).

---

## ğŸ“ˆ Workflow Summary
1. **Load & Augment** images (rotation, zoom, shear).  
2. **Shuffle & Flatten** to 30k features / image.  
3. **PCA (95%)** â†’ 2,034 components.  
4. **Train/Test Split** (70/30, stratified) + **Standardization**.  
5. **Model Zoo**: SGD, Logistic Regression, AdaBoost, Random Forest, SVM.  
6. **Evaluate** via accuracy + classification reports.  
7. **Persist** best model with `pickle`.

---

## ğŸ§ª Reproducibility

### Requirements
- Python 3.10+
- `numpy`, `pandas`, `scikit-learn`, `matplotlib`
- (For augmentation) `tensorflow` / `keras`

```bash
pip install -r requirements.txt
# or
pip install numpy pandas scikit-learn matplotlib tensorflow
```

### Data Layout (example)
```
project/
â”œâ”€ Images/
â”‚  â”œâ”€ original/            # raw signatures per signer ID
â”‚  â”œâ”€ augmented1/          # generated by the notebook
â”‚  â”œâ”€ augmented2/
â”‚  â””â”€ ... augmented9/
â”œâ”€ notebooks/
â”‚  â””â”€ Final_Model_DS.ipynb
â”œâ”€ models/
â”‚  â”œâ”€ svm_model.pkl
â”‚  â””â”€ scaler.pkl
â””â”€ README.md
```

### Train & Evaluate (outline)
```python
# 1) Flatten images and build X, y
# 2) PCA to keep 95% variance (â‰ˆ 2034 comps)
# 3) Split (train/test = 70/30, stratified) + StandardScaler
# 4) Fit SVM (rbf, class_weight='balanced')
# 5) Evaluate: accuracy + classification_report
# 6) Save model with pickle
```
---

## ğŸ” Key Results (From Notebook)
- **Dataset**: 21,120 images â†’ PCA to 2,034 components.  
- **Test Set**: 6,336 images (30%).  
- **Best Model**: **SVM (RBF)** with **~0.80 accuracy** and balanced weighted precision/recall/F1.  
- **Baselines**: Random Forest (~0.71), AdaBoost (~0.51), Logistic & SGD (~0.39).

---

## ğŸš€ Future Work
- **Deep Learning**: Convolutional/Siamese networks for metric learning and writer verification.  
- **Better Features**: CNN embeddings instead of raw pixel flattening.  
- **Data Expansion**: More authentic signature variety; augmentation tuned per signer.  
- **Calibration**: Probability calibration & thresholding for decision support.  
- **Deployment**: REST API + UI to upload signatures and receive verification results.

---
## âœï¸ Author
Jeremy Okocha â€” MSBA, Data Analyst & ML Enthusiast  
*Signature Verification Project*
